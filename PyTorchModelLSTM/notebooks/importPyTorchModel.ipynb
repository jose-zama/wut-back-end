{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from spacy.lang.en.examples import sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Declare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Model(nn.Module):\n",
    "    def __init__(self,op_size,n_tokens,pretrained_vectors,nl=2,bidirectional=True,emb_sz=300,n_hiddenUnits=100):\n",
    "        super(LSTM_Model, self).__init__()\n",
    "        self.n_hidden= n_hiddenUnits\n",
    "        self.embeddings= nn.Embedding(n_tokens,emb_sz)\n",
    "        self.embeddings.weight.data.copy_(pretrained_vectors)\n",
    "#         self.embeddings.weight.requires_grad = False\n",
    "        self.rnn= nn.LSTM(emb_sz,n_hiddenUnits,num_layers=2,bidirectional=True,dropout=0.2)\n",
    "        self.lArr=[]\n",
    "        if bidirectional:\n",
    "            n_hiddenUnits= 2* n_hiddenUnits\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=n_hiddenUnits)\n",
    "        for i in range(nl):\n",
    "            if i==0:\n",
    "                self.lArr.append(nn.Linear(n_hiddenUnits*3,n_hiddenUnits))\n",
    "            else:\n",
    "                self.lArr.append(nn.Linear(n_hiddenUnits,n_hiddenUnits))\n",
    "        self.lArr= nn.ModuleList(self.lArr)\n",
    "        self.l1= nn.Linear(n_hiddenUnits,op_size)\n",
    "        \n",
    "    def forward(self,data,lengths):\n",
    "        #torch.gpu().empty_cache()\n",
    "        bs= data.shape[1]\n",
    "        self.h= self.init_hidden(bs)\n",
    "        embedded= self.embeddings(data)\n",
    "        embedded= nn.Dropout()(embedded)\n",
    "        #embedded = pack_padded_sequence(embedded, torch.as_tensor(lengths)) #\n",
    "        rnn_out, self.h = self.rnn(embedded, (self.h,self.h))\n",
    "        #rnn_out, lengths = pad_packed_sequence(rnn_out,padding_value=1) #\n",
    "        avg_pool= F.adaptive_avg_pool1d(rnn_out.permute(1,2,0),1).view(bs,-1)\n",
    "        max_pool= F.adaptive_max_pool1d(rnn_out.permute(1,2,0),1).view(bs,-1)\n",
    "        ipForLinearLayer= torch.cat([avg_pool,max_pool,rnn_out[-1]],dim=1)\n",
    "        for linearlayer in self.lArr:\n",
    "            outp= linearlayer(ipForLinearLayer)\n",
    "            ipForLinearLayer= self.bn1(F.relu(outp))\n",
    "            ipForLinearLayer= nn.Dropout(p=0.6)(ipForLinearLayer)\n",
    "        outp = self.l1(ipForLinearLayer)\n",
    "        del embedded;del rnn_out;del self.h;\n",
    "        #torch.gpu().empty_cache()\n",
    "        return outp\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((4,batch_size,self.n_hidden),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Upload the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pd.read_csv(\"Datasets/train.csv\")\n",
    "columns = columns.columns[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load work embeddings english and spanish from spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tok = spacy.load('en_core_web_sm')\n",
    "my_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "STOPWORDS = set(stopwords.words('spanish'))\n",
    "my_stopwords.update(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tok(x):\n",
    "    x= re.sub(r'[^a-zA-Z\\s]','',x)\n",
    "    x= re.sub(r'[\\n]','',x)\n",
    "    return [tok.text for tok in my_tok.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up Text and Label to read csv files as torchText Tabular Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tok,eos_token='EOS',stop_words=my_stopwords,include_lengths=True)\n",
    "LABEL = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                            unk_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFields = [(\"Details\", TEXT),\n",
    "             (\"Auto & Transport\", LABEL), (\"Bills & Utilities\", LABEL),\n",
    "             (\"Entertainment\", LABEL), (\"Fees & Charges\", LABEL),  \n",
    "             (\"Food & Dining\", LABEL), (\"Gifts & Donations\", LABEL),\n",
    "             (\"Health & Fitness\", LABEL), (\"Shopping\", LABEL),\n",
    "             (\"Transfer\", LABEL), (\"Travel\", LABEL), (\"Withdrawal\", LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = data.TabularDataset.splits(path=\"Datasets/\",train=\"train.csv\", validation=\"val.csv\", format=\"csv\", fields=dataFields, skip_header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train,val, vectors=['fasttext.simple.300d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert tabular dataset to vocabulary vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors= train.fields['Details'].vocab.vectors.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM_Model(len(columns),len(TEXT.vocab),vectors,1)\n",
    "model.load_state_dict(torch.load(\"LSTM_transactions_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read csv test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv(\"Datasets/test.csv\")\n",
    "dataFields = [(\"Details\", TEXT)]\n",
    "testDataset= data.TabularDataset(path='Datasets/test.csv', \n",
    "                                            format='csv',\n",
    "                                            fields=dataFields, \n",
    "                                            skip_header=True)\n",
    "test_iter1 = torchtext.data.Iterator(testDataset, batch_size=32, device=torch.device('cpu'), sort=False, sort_within_batch=False, repeat=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds=[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for obj in test_iter1:\n",
    "        text= torch.transpose(obj.Details[0],0,1)[:2]\n",
    "        pred= model(obj.Details[0],obj.Details[1])        \n",
    "        pred= torch.sigmoid(pred)\n",
    "        myPreds.append(pred.detach().numpy())\n",
    "        del pred;del obj;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds= np.vstack(myPreds)\n",
    "for i, col in enumerate(columns):\n",
    "    dfTest[col] = myPreds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(columns):\n",
    "    dfTest[col] = myPreds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOfCategories = { i : columns[i] for i in range(0, len(columns) ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "for i in range(dfTest.shape[0]):\n",
    "    best.append(dictOfCategories[dfTest.iloc[i,1:].values.argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output predictions on a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest[\"Prediction\"] = best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = dfTest[[\"Details\",\"Prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest.to_csv(\"Datasets/output.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8150123131lgr 150220p98cafe baristi cosm</td>\n",
       "      <td>Food &amp; Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8150123130fosa860123fi1rest public house</td>\n",
       "      <td>Food &amp; Dining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>paypal uber bv 35314369001 nl</td>\n",
       "      <td>Auto &amp; Transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paypal uber bv 35314369001 nl</td>\n",
       "      <td>Auto &amp; Transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>paypal uber bv 35314369001 nl</td>\n",
       "      <td>Auto &amp; Transport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Details        Prediction\n",
       "0  8150123131lgr 150220p98cafe baristi cosm     Food & Dining\n",
       "1  8150123130fosa860123fi1rest public house     Food & Dining\n",
       "2             paypal uber bv 35314369001 nl  Auto & Transport\n",
       "3             paypal uber bv 35314369001 nl  Auto & Transport\n",
       "4             paypal uber bv 35314369001 nl  Auto & Transport"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"Datasets/output.csv\").head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
