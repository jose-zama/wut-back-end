{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torch\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "import spacy\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.examples import sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tok = spacy.load('en_core_web_sm')\n",
    "my_stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_tok(x):\n",
    "    x= re.sub(r'[^a-zA-Z\\s]','',x)\n",
    "    x= re.sub(r'[\\n]','',x)\n",
    "    #x = re.sub(r'[A-Za-z]+|\\d+',x)\n",
    "    #SPLIT_NUMBERS = re.compile(r'([+-]?\\d*\\.?\\d+(?:[eE][-+]?\\d+)?)')\n",
    "    #x = ' '.join(SPLIT_NUMBERS.split(x))\n",
    "    return [tok.text for tok in my_tok.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=spacy_tok,eos_token='EOS',stop_words=my_stopwords,include_lengths=True)\n",
    "LABEL = data.Field(sequential=False, \n",
    "                         use_vocab=False, \n",
    "                         pad_token=None, \n",
    "                            unk_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Datasets/training-data.csv\", header = 0, names=[\"Category\", \"Details\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(pd.get_dummies(df[\"Category\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Category\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.rename(columns={\"Auto & Transport\":\"Auto_and_Transport\", \"Bills & Utilities\":\"Bills_and_Utilities\", \"Fees & Charges\":\"Fees_and_Charges\", \"Food & Dining\":\"Food_and_Dining\", \"Gifts & Donations\":\"Gifts_and_Donations\", \"Health & Fitness\":\"Health_and_Fitness\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "      <th>Auto &amp; Transport</th>\n",
       "      <th>Bills &amp; Utilities</th>\n",
       "      <th>Entertainment</th>\n",
       "      <th>Fees &amp; Charges</th>\n",
       "      <th>Food &amp; Dining</th>\n",
       "      <th>Gifts &amp; Donations</th>\n",
       "      <th>Health &amp; Fitness</th>\n",
       "      <th>Shopping</th>\n",
       "      <th>Transfer</th>\n",
       "      <th>Travel</th>\n",
       "      <th>Withdrawal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>REST PUBLIC HOUSE 2 TIJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8254833557VPC 160113L21DANTES GASTROMED</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7412040258EINI5408116L9REST DAS CORTEZ C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>58522132620267080680112REST PUBLIC HOUSE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9497635894DCA 0105286Q2LA EUROPEA  molestias</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Details  Auto & Transport  \\\n",
       "0                       REST PUBLIC HOUSE 2 TIJ                 0   \n",
       "1       8254833557VPC 160113L21DANTES GASTROMED                 0   \n",
       "2      7412040258EINI5408116L9REST DAS CORTEZ C                 0   \n",
       "3      58522132620267080680112REST PUBLIC HOUSE                 0   \n",
       "4  9497635894DCA 0105286Q2LA EUROPEA  molestias                 0   \n",
       "\n",
       "   Bills & Utilities  Entertainment  Fees & Charges  Food & Dining  \\\n",
       "0                  0              0               0              1   \n",
       "1                  0              0               0              1   \n",
       "2                  0              0               0              1   \n",
       "3                  0              0               0              1   \n",
       "4                  0              0               0              1   \n",
       "\n",
       "   Gifts & Donations  Health & Fitness  Shopping  Transfer  Travel  Withdrawal  \n",
       "0                  0                 0         0         0       0           0  \n",
       "1                  0                 0         0         0       0           0  \n",
       "2                  0                 0         0         0       0           0  \n",
       "3                  0                 0         0         0       0           0  \n",
       "4                  0                 0         0         0       0           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"Datasets/train.csv\", index_label=False, index=False)\n",
    "val.to_csv(\"Datasets/val.csv\", index_label=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFields = [(\"Details\", TEXT),\n",
    "             (\"Auto & Transport\", LABEL), (\"Bills & Utilities\", LABEL),\n",
    "             (\"Entertainment\", LABEL), (\"Fees & Charges\", LABEL),  \n",
    "             (\"Food & Dining\", LABEL), (\"Gifts & Donations\", LABEL),\n",
    "             (\"Health & Fitness\", LABEL), (\"Shopping\", LABEL),\n",
    "             (\"Transfer\", LABEL), (\"Travel\", LABEL), (\"Withdrawal\", LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,val = data.TabularDataset.splits(path=\"Datasets/\",train=\"train.csv\", validation=\"val.csv\", format=\"csv\", fields=dataFields, skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vec = torchtext.vocab.Vectors('cc.es.300.vec', cache='./Datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.build_vocab(train,val, vectors=['fasttext.simple.300d',vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train,val, vectors=['fasttext.simple.300d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2863"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindl, valdl = torchtext.data.BucketIterator.splits(datasets=(train, val),\n",
    "                                            batch_sizes=(64, 64),\n",
    "                                            sort_key=lambda x: len(x.Details),\n",
    "                                            device=torch.device('cpu'),\n",
    "                                            sort_within_batch=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors= train.fields['Details'].vocab.vectors.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "    def __init__(self, dl):\n",
    "        self.dl = dl\n",
    "        self.yFields= df.columns[1:]\n",
    "        self.x= 'Details'\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            X = getattr(batch, self.x)\n",
    "            y = torch.transpose( torch.stack([getattr(batch, y) for y in self.yFields]),0,1)\n",
    "            yield (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self,op_size,n_tokens,pretrained_vectors,nl=2,bidirectional=True,emb_sz=300,n_hiddenUnits=100):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.n_hidden= n_hiddenUnits\n",
    "        self.embeddings= nn.Embedding(n_tokens,emb_sz)\n",
    "        self.embeddings.weight.data.copy_(pretrained_vectors)\n",
    "#         self.embeddings.weight.requires_grad = False\n",
    "        self.rnn= nn.LSTM(emb_sz,n_hiddenUnits,num_layers=2,bidirectional=True,dropout=0.2)\n",
    "        self.lArr=[]\n",
    "        if bidirectional:\n",
    "            n_hiddenUnits= 2* n_hiddenUnits\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=n_hiddenUnits)\n",
    "        for i in range(nl):\n",
    "            if i==0:\n",
    "                self.lArr.append(nn.Linear(n_hiddenUnits*3,n_hiddenUnits))\n",
    "            else:\n",
    "                self.lArr.append(nn.Linear(n_hiddenUnits,n_hiddenUnits))\n",
    "        self.lArr= nn.ModuleList(self.lArr)\n",
    "        self.l1= nn.Linear(n_hiddenUnits,op_size)\n",
    "        \n",
    "    def forward(self,data,lengths):\n",
    "        #torch.to(\"cpu\").empty_cache()\n",
    "        bs= data.shape[1]\n",
    "        self.h= self.init_hidden(bs)\n",
    "        embedded= self.embeddings(data)\n",
    "        embedded= nn.Dropout()(embedded)\n",
    "        #embedded = pack_padded_sequence(embedded, torch.as_tensor(lengths)) #\n",
    "        rnn_out, self.h = self.rnn(embedded, (self.h,self.h))\n",
    "        #rnn_out, lengths = pad_packed_sequence(rnn_out,padding_value=1) #\n",
    "        avg_pool= F.adaptive_avg_pool1d(rnn_out.permute(1,2,0),1).view(bs,-1)\n",
    "        max_pool= F.adaptive_max_pool1d(rnn_out.permute(1,2,0),1).view(bs,-1)\n",
    "        ipForLinearLayer= torch.cat([avg_pool,max_pool,rnn_out[-1]],dim=1)\n",
    "        for linearlayer in self.lArr:\n",
    "            outp= linearlayer(ipForLinearLayer)\n",
    "            ipForLinearLayer= self.bn1(F.relu(outp))\n",
    "            ipForLinearLayer= nn.Dropout(p=0.6)(ipForLinearLayer)\n",
    "        outp = self.l1(ipForLinearLayer)\n",
    "        del embedded;del rnn_out;del self.h;\n",
    "        #torch.to(\"cpu\").empty_cache()\n",
    "        return outp\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((4,batch_size,self.n_hidden),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getValidationLoss(valdl,model,loss_func):\n",
    "    model.eval()\n",
    "    runningLoss=0\n",
    "    valid_batch_it = BatchGenerator(valdl)\n",
    "    allPreds= []\n",
    "    allActualPreds= []\n",
    "    with torch.no_grad():\n",
    "        for i,obj in enumerate(valid_batch_it):\n",
    "            obj= ( (obj[0][0].to(\"cpu\"),obj[0][1].to(\"cpu\")),obj[1] )\n",
    "            preds = model(obj[0][0],obj[0][1])\n",
    "            loss = loss_func(preds,obj[1].float())\n",
    "            runningLoss+= loss.item()\n",
    "            allPreds.append(preds.detach().numpy())\n",
    "            allActualPreds.append(obj[1].detach().numpy())\n",
    "        rocLoss= roc_auc_score(np.vstack(allActualPreds),np.vstack(allPreds), average=\"micro\")\n",
    "        return runningLoss/len(valid_batch_it),rocLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n",
    "def oneEpoch(lr):\n",
    "    train_batch_it = BatchGenerator(traindl)\n",
    "    opt = optim.Adam(model.parameters(),lr)\n",
    "    runningLoss= 0\n",
    "    allPreds=[]\n",
    "    allActualPreds=[]\n",
    "    for i,obj in enumerate(train_batch_it):\n",
    "        obj= ( (obj[0][0].to(\"cpu\"),obj[0][1].to(\"cpu\")),obj[1] )\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        preds = model(obj[0][0],obj[0][1])\n",
    "        loss = loss_func(preds,obj[1].float())\n",
    "        runningLoss+= loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        allPreds.append(preds.detach().numpy())\n",
    "        allActualPreds.append(obj[1].detach().numpy())\n",
    "        del obj;del preds\n",
    "    trainRocLoss= roc_auc_score(np.vstack(allActualPreds),np.vstack(allPreds), average=\"micro\")\n",
    "    runningLoss= runningLoss/len(train_batch_it)\n",
    "    valLoss,valRocLoss= getValidationLoss(valdl,model,loss_func)\n",
    "    torch.cuda.empty_cache()\n",
    "    return runningLoss,valLoss,trainRocLoss,valRocLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 1.86 s, total: 53 s\n",
      "Wall time: 5.19 s\n",
      "Epoch - 0\n",
      "Train Loss - 0.6695120593775874 vs Val Loss is 0.6276562213897705\n",
      "Train ROC - 0.7693400929752067 vs Val ROC is 0.867627861570248\n",
      "CPU times: user 51.7 s, sys: 1.7 s, total: 53.4 s\n",
      "Wall time: 5.13 s\n",
      "Epoch - 1\n",
      "Train Loss - 0.5993452897106392 vs Val Loss is 0.5702847599983215\n",
      "Train ROC - 0.8898218278667356 vs Val ROC is 0.9084915289256199\n",
      "CPU times: user 54.2 s, sys: 1.99 s, total: 56.2 s\n",
      "Wall time: 5.43 s\n",
      "Epoch - 2\n",
      "Train Loss - 0.5409396534812623 vs Val Loss is 0.5027064153126308\n",
      "Train ROC - 0.9219483935950414 vs Val ROC is 0.935451590909091\n",
      "CPU times: user 55.1 s, sys: 1.48 s, total: 56.5 s\n",
      "Wall time: 5.34 s\n",
      "Epoch - 3\n",
      "Train Loss - 0.48127008909764496 vs Val Loss is 0.4426100790500641\n",
      "Train ROC - 0.9352385847107437 vs Val ROC is 0.9336237603305786\n",
      "CPU times: user 55.4 s, sys: 1.73 s, total: 57.1 s\n",
      "Wall time: 5.47 s\n",
      "Epoch - 4\n",
      "Train Loss - 0.4192818772533666 vs Val Loss is 0.38547778044428144\n",
      "Train ROC - 0.9474928635072315 vs Val ROC is 0.9536925206611571\n",
      "CPU times: user 55.9 s, sys: 1.69 s, total: 57.6 s\n",
      "Wall time: 5.48 s\n",
      "Epoch - 5\n",
      "Train Loss - 0.35721317387145496 vs Val Loss is 0.3175291155065809\n",
      "Train ROC - 0.9534585156250001 vs Val ROC is 0.9625168595041321\n",
      "CPU times: user 55.8 s, sys: 2.44 s, total: 58.2 s\n",
      "Wall time: 5.8 s\n",
      "Epoch - 6\n",
      "Train Loss - 0.29796309779951535 vs Val Loss is 0.2551673723118646\n",
      "Train ROC - 0.959361085356405 vs Val ROC is 0.9675853719008265\n",
      "CPU times: user 56.3 s, sys: 2.59 s, total: 58.9 s\n",
      "Wall time: 5.78 s\n",
      "Epoch - 7\n",
      "Train Loss - 0.24518257066391516 vs Val Loss is 0.21651148072310855\n",
      "Train ROC - 0.9633547559400827 vs Val ROC is 0.9718293595041321\n",
      "CPU times: user 56.5 s, sys: 1.7 s, total: 58.2 s\n",
      "Wall time: 5.53 s\n",
      "Epoch - 8\n",
      "Train Loss - 0.1976881894296494 vs Val Loss is 0.17167366104466575\n",
      "Train ROC - 0.9662943317407026 vs Val ROC is 0.9818725309917355\n",
      "CPU times: user 56.5 s, sys: 1.4 s, total: 57.9 s\n",
      "Wall time: 5.44 s\n",
      "Epoch - 9\n",
      "Train Loss - 0.16017245841415031 vs Val Loss is 0.14232097289391926\n",
      "Train ROC - 0.9694361731663224 vs Val ROC is 0.9869982024793388\n"
     ]
    }
   ],
   "source": [
    "epochs= 10\n",
    "trainLossArr=[]\n",
    "valLossArr=[]\n",
    "rocTrainLoss=[]\n",
    "rocValLoss=[]\n",
    "model= MyModel(11,len(TEXT.vocab),vectors,1)\n",
    "loss_func= torch.nn.BCEWithLogitsLoss()\n",
    "model = model.to(\"cpu\")\n",
    "for i in range(epochs):\n",
    "    %time tLoss,vLoss,tRocLoss,vRocLoss= oneEpoch(1e-4)\n",
    "    print(f\"Epoch - {i}\")\n",
    "    print(f\"Train Loss - {tLoss} vs Val Loss is {vLoss}\")\n",
    "    print(f\"Train ROC - {tRocLoss} vs Val ROC is {vRocLoss}\")\n",
    "    trainLossArr.append(tLoss)\n",
    "    valLossArr.append(vLoss)\n",
    "    rocTrainLoss.append(tRocLoss)\n",
    "    rocValLoss.append(vRocLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot(trainLossArr,color='b')\n",
    "plt.plot(valLossArr,color='g')\n",
    "plt.plot(rocTrainLoss,color='r')\n",
    "plt.plot(rocValLoss,color='c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"LSTM_transactions_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = pd.read_csv(\"Datasets/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8150123131lgr 150220p98cafe baristi cosm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8150123130fosa860123fi1rest public house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>paypal uber bv 35314369001 nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>paypal uber bv 35314369001 nl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>paypal uber bv 35314369001 nl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Details\n",
       "0  8150123131lgr 150220p98cafe baristi cosm\n",
       "1  8150123130fosa860123fi1rest public house\n",
       "2             paypal uber bv 35314369001 nl\n",
       "3             paypal uber bv 35314369001 nl\n",
       "4             paypal uber bv 35314369001 nl"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataFields = [(\"Details\", TEXT)]\n",
    "\n",
    "testDataset= data.TabularDataset(path='Datasets/test.csv', \n",
    "                                            format='csv',\n",
    "                                            fields=dataFields, \n",
    "                                            skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter1 = torchtext.data.Iterator(testDataset, batch_size=32, device=torch.device('cpu'), sort=False, sort_within_batch=False, repeat=False,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds=[]\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for obj in test_iter1:\n",
    "        text= torch.transpose(obj.Details[0],0,1)[:2]\n",
    "        pred= model(obj.Details[0],obj.Details[1])        \n",
    "        pred= torch.sigmoid(pred)\n",
    "        myPreds.append(pred.detach().numpy())\n",
    "        del pred;del obj;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPreds= np.vstack(myPreds)\n",
    "for i, col in enumerate(df.columns[1:]):\n",
    "    dfTest[col] = myPreds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df.columns[1:]):\n",
    "    dfTest[col] = myPreds[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictOfCategories = { i : dfTest.columns[1:][i] for i in range(0, len(dfTest.columns[1:]) ) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "for i in range(dfTest.shape[0]):\n",
    "    best.append(dictOfCategories[dfTest.iloc[i,1:].values.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest[\"Prediction\"] = best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = dfTest[[\"Details\",\"Prediction\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest.to_csv(\"testPredictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchenv",
   "language": "python",
   "name": "pytorchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
